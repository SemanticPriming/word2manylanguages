{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db83c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98436152",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.join('Y:\\\\', 'Dissertation')\n",
    "countdir = \"frequencies\"\n",
    "modeldir = 'models'\n",
    "evaldir = 'count_evals'\n",
    "scoredir = 'count_scores'\n",
    "\n",
    "scorepath = os.path.join(basedir, scoredir)\n",
    "if not os.path.exists(scorepath):\n",
    "    os.makedirs(scorepath)\n",
    "    \n",
    "evalpath = os.path.join(basedir, evaldir)\n",
    "if not os.path.exists(evalpath):\n",
    "    os.makedirs(evalpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956e8e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model en_50_1_sg from Y:\\Dissertation\\models\\en_50_1_sg_wxd.csv\n"
     ]
    }
   ],
   "source": [
    "lang = 'en'\n",
    "dim = 50\n",
    "win = 1\n",
    "alg = 'sg'\n",
    "# en_50_1_sg_wxd\n",
    "\n",
    "base_file_name = f'{lang}_{str(dim)}_{str(win)}_{alg}'\n",
    "input_path = os.path.join(basedir, modeldir, f'{base_file_name}_wxd.csv')\n",
    "print(\"Loading model \" + base_file_name + \" from \" + input_path)\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as vecfile:\n",
    "    # skip header\n",
    "    next(vecfile)\n",
    "    # initialize arrays\n",
    "    vectors = np.zeros((10000000, dim))\n",
    "    words = np.empty(10000000, dtype=object) # fill arrays\n",
    "    for i, line in enumerate(vecfile):\n",
    "        # Limit to 10 million, although it looks like 7.5 million is the largest\n",
    "        if i >= 10000000:\n",
    "            break\n",
    "        #print(line)\n",
    "        rowentries = line.rstrip('\\n').split(',')\n",
    "        words[i] = rowentries[0].casefold()\n",
    "        vectors[i] = rowentries[1:dim+1]\n",
    "\n",
    "    # truncate empty part of arrays, if necessary\n",
    "    vectors = vectors[:i]\n",
    "    words = words[:i] \n",
    "\n",
    "    # normalize by L1 norm\n",
    "    vectors = vectors / np.linalg.norm(vectors, axis=1).reshape(-1, 1)\n",
    "\n",
    "    wordsXdims = pd.DataFrame(vectors)\n",
    "    wordsXdims.set_index(words, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b38e4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dedup.en.words.unigrams.tsv\n"
     ]
    }
   ],
   "source": [
    "langfile=f'dedup.{lang}.words.unigrams.tsv'\n",
    "datasetspath = os.path.join(basedir,countdir)\n",
    "\n",
    "print('Loading ' + langfile)\n",
    "datapath = os.path.join(datasetspath,langfile)\n",
    "freqs = pd.read_csv(datapath,sep='\\t', comment='#', na_values=['-','–'])\n",
    "freqs.set_index('unigram', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aaf45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_index = list(freqs.index.values)\n",
    "wxd_index = list(wordsXdims.index.values)\n",
    "\n",
    "missing = []\n",
    "n = 0\n",
    "for f in freqs_index:\n",
    "    if f not in wxd_index: \n",
    "        missing.append(f)\n",
    "        n += 1\n",
    "        if (n >= 25): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9429ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, 'ß', nan, 'ﬂoor', 'ﬁrst', 'ﬂy', 'ﬁnd', 'okay\\xa0', 'µ', 'ﬂ', 'ﬂight', 'ﬂying', 'ﬂowers', 'huh\\xa0', 'what\\xa0', 'ﬁne', 'ﬂat', 'ﬁre', 'ﬂower', 'ﬂesh', 'ﬂag', 'ﬁght', 'ﬁve', 'riﬂe']\n"
     ]
    }
   ],
   "source": [
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5fc470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, 'ß', nan, 'floor', 'first', 'fly', 'find', 'okay ', 'μ', 'fl', 'flight', 'flying', 'flowers', 'huh ', 'what ', 'fine', 'flat', 'fire', 'flower', 'flesh', 'flag', 'fight', 'five', 'rifle']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "i = 0\n",
    "while i < len(missing):\n",
    "    if (isinstance(missing[i], str)):\n",
    "        missing[i] = unicodedata.normalize(\"NFKD\", missing[i])\n",
    "    i += 1\n",
    "    \n",
    "print(missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b3146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(missing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eace8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(freqs_index):\n",
    "    if (isinstance(freqs_index[i], str)):\n",
    "        freqs_index[i] = unicodedata.normalize(\"NFKD\", freqs_index[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2474bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: 7577800  freqs: 2397981  matches: 1360559\n",
      "missing vectors for 1037422 out of 2397981 words\n"
     ]
    }
   ],
   "source": [
    "freqs.index = freqs_index\n",
    "\n",
    "df = freqs.join(wordsXdims, how='inner')\n",
    "    \n",
    "# compensate for missing ys somehow\n",
    "total = len(freqs)\n",
    "missing = len(freqs) - len(df)\n",
    "penalty = (total - missing) / total\n",
    "print(f'vectors: {len(wordsXdims)}  freqs: {total}  matches: {len(df)}')\n",
    "print(f'missing vectors for {missing} out of {total} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7522002",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_index = list(freqs.index.values)\n",
    "\n",
    "missing = []\n",
    "n = 0\n",
    "for f in freqs_index:\n",
    "    if f not in wxd_index: \n",
    "        missing.append(f)\n",
    "        n += 1\n",
    "        if (n >= 25): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac5e92c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'yöu', 'âa', 'yöur', 'ü', 'fiancée', 'fiancé', 'café', 'señor', 'é', nan, 'ó', 'josé', 'à', 'â', 'führer', 'françois', 'andré', 'cliché', 'não', 'résumé', 'rené', 'sátur', 'maría', 'qué']\n"
     ]
    }
   ],
   "source": [
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14fe1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "i = 0\n",
    "while i < len(freqs_index):\n",
    "    if (isinstance(freqs_index[i], str)):\n",
    "        freqs_index[i] = unidecode(freqs_index[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b305c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: 7577800  freqs: 2397981  matches: 1476478\n",
      "missing vectors for 921503 out of 2397981 words\n"
     ]
    }
   ],
   "source": [
    "freqs.index = freqs_index\n",
    "\n",
    "df = freqs.join(wordsXdims, how='inner')\n",
    "    \n",
    "# compensate for missing ys somehow\n",
    "total = len(freqs)\n",
    "missing = len(freqs) - len(df)\n",
    "penalty = (total - missing) / total\n",
    "print(f'vectors: {len(wordsXdims)}  freqs: {total}  matches: {len(df)}')\n",
    "print(f'missing vectors for {missing} out of {total} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "691ae402",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_index = list(freqs.index.values)\n",
    "\n",
    "missing = []\n",
    "n = 0\n",
    "for f in freqs_index:\n",
    "    if f not in wxd_index: \n",
    "        missing.append(f)\n",
    "        n += 1\n",
    "        if (n >= 25): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05b106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, 'you ', 'right ', 'atrademarka', 'yyand', 'it ', '1/2', 'that ', 'aeaeaaduoae', 'me ', 'yythe', 'okay ', 'here ', 'yyit', 'yyyyyyi', 'yyto', 'yyyi', 'yyyyi', 'yywe', 'i1/2', 'varnaes', 'this ', 'enerything']\n"
     ]
    }
   ],
   "source": [
    "print(missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a92b28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(freqs_index):\n",
    "    if (isinstance(freqs_index[i], str)):\n",
    "        freqs_index[i] = freqs_index[i].strip()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30d0fb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: 7577800  freqs: 2397981  matches: 1490117\n",
      "missing vectors for 907864 out of 2397981 words\n"
     ]
    }
   ],
   "source": [
    "freqs.index = freqs_index\n",
    "\n",
    "df = freqs.join(wordsXdims, how='inner')\n",
    "    \n",
    "# compensate for missing ys somehow\n",
    "total = len(freqs)\n",
    "missing = len(freqs) - len(df)\n",
    "penalty = (total - missing) / total\n",
    "print(f'vectors: {len(wordsXdims)}  freqs: {total}  matches: {len(df)}')\n",
    "print(f'missing vectors for {missing} out of {total} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "307776c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_index = list(freqs.index.values)\n",
    "\n",
    "missing = []\n",
    "n = 0\n",
    "for f in freqs_index:\n",
    "    if f not in wxd_index: \n",
    "        missing.append(f)\n",
    "        n += 1\n",
    "        if (n >= 25): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "818a1d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, 'atrademarka', 'yyand', '1/2', 'aeaeaaduoae', 'yythe', 'yyit', 'yyyyyyi', 'yyto', 'yyyi', 'yyyyi', 'yywe', 'i1/2', 'varnaes', 'enerything', 'woulive', 'seoor', 'yythat', 'korsbaek', 'yybut', 'coulive', 'shoulive', 'yywhat']\n"
     ]
    }
   ],
   "source": [
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c097a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: 7577800  freqs: 406868  matches: 761046\n",
      "missing vectors for -354178 out of 406868 words\n"
     ]
    }
   ],
   "source": [
    "freqs = freqs[freqs.unigram_freq >= 5]\n",
    "df = freqs.join(wordsXdims, how='inner')\n",
    "    \n",
    "# compensate for missing ys somehow\n",
    "total = len(freqs)\n",
    "missing = len(freqs) - len(df)\n",
    "penalty = (total - missing) / total\n",
    "print(f'vectors: {len(wordsXdims)}  freqs: {total}  matches: {len(df)}')\n",
    "print(f'missing vectors for {missing} out of {total} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52794a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
